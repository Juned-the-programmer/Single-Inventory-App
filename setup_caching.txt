# To setup Cache

Install memchached in local or production server.

sudo dnf install memcached

sudo systemctl start memcached

sudo systemctl enable memcached

sudo systemctl status memcached

pip3 install pymemcached


Other than this code is already in the codebase for caching.


Certainly, retrieving data for large datasets can be challenging, and optimizing the process is important. 
Here are some suggestions to make this process more efficient:

Database Indexing: 
Ensure that the relevant fields, such as customer and product_name, are indexed in your database. This can significantly speed up querying large datasets.

Query Optimization: 
Instead of querying multiple times in the loop, try to perform fewer queries by using filters and aggregations. For example, you can filter estimatesales_Product to get the latest rate for a specific customer and product.

Caching: 
Consider implementing caching mechanisms to store frequently accessed data temporarily. Django provides caching frameworks that can help improve response times for repeated queries.

Data Aggregation: 
If possible, store aggregated data like the latest rate per customer-product pair in a separate table or cache. This would eliminate the need to repeatedly query historical data.

Batch Processing: 
Depending on your use case, you might benefit from processing data in batches instead of real-time. You could periodically update aggregated data or calculate selling prices in bulk.

Database Denormalization: 
If querying performance is a major concern, you could consider denormalizing data by storing historical product rates directly within the Estimate_sales table. This way, you wouldn't need to perform additional queries.

Background Jobs: 
Use tools like Celery to handle resource-intensive tasks in the background, freeing up server resources for serving requests.

Database Sharding and Partitioning: 
For extremely large datasets, consider database sharding (splitting data across multiple databases) or partitioning (dividing data within a single database into smaller manageable chunks).

Database Profiling: 
Profile your database queries to identify slow queries and optimize them. Django Debug Toolbar can help you visualize and analyze query performance.

Database Scaling: 
If your dataset is continually growing and you're experiencing performance issues, consider horizontal scaling by adding read replicas or using a database cluster.


# To setup celery

sudo dnf install python3-devel

sudo dnf install redis

pip3 install celery redis


# To start the celery tasks

# Start the redis server
redis-server

# start celery worker
celery -A Inventory worker --loglevel=debug

# start celery beat
celery -A Inventory beat --loglevel=debug









product1 = Product.objects.create(name='Product A', description='Description of Product A')
product2 = Product.objects.create(name='Product B', description='Description of Product B')
product3 = Product.objects.create(name='Product C', description='Description of Product C')

product1.required_products.add(product2, product3)
product2.required_products.add(product3)

required_products_for_product1 = product1.required_products.all()

# Find products required for 'Product A'
products_required_for_product1 = Product.objects.filter(required_products=product1)

# Find products that require 'Product B'
products_requiring_product2 = Product.objects.filter(required_products=product2)